{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca37fcf2",
   "metadata": {},
   "source": [
    "## Compute the Global Feature Rankings \n",
    "\n",
    "In this notebook, we compute the global feature rankings. The methods include:\n",
    "1. PD and ALE variance (PAPER)\n",
    "2. Backward Single-pass Permutation Importance \n",
    "3. Forward Single-pass Permutation Importance \n",
    "4. Backward Multi-pass Permutation Importance  \n",
    "5. Forward Multi-pass Permutation Importance \n",
    "6. Random Forest Gini Impurity \n",
    "7. Logistic Regression Coefficients \n",
    "8. Summed SHAP values \n",
    "9. SAGE values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7212a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os \n",
    "from os.path import dirname\n",
    "path = dirname(dirname(os.getcwd()))\n",
    "sys.path.insert(0, path)\n",
    "sys.path.insert(0, '/home/monte.flora/python_packages/scikit-explain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d022dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skexplain \n",
    "from skexplain.common.importance_utils import to_skexplain_importance\n",
    "from src.io.io import load_data_and_model\n",
    "from src.common.util import subsampler, normalize_importance, compute_sage\n",
    "\n",
    "import pickle\n",
    "import shap\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08e8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants. \n",
    "N_BOOTSTRAP = 1\n",
    "N_BINS = 20 \n",
    "N_JOBS = 30 \n",
    "N_PERMUTE = 5\n",
    "SIZE = 5000\n",
    "EVALUATION_FN = 'norm_aupdc'\n",
    "RESULTS_PATH = os.path.join(path, 'results')\n",
    "BASE_PATH = '/work/mflora/explainability_work/'\n",
    "DATA_BASE_PATH = os.path.join(BASE_PATH, 'datasets')\n",
    "MODEL_BASE_PATH = os.path.join(BASE_PATH, 'models')\n",
    "\n",
    "DATASETS = ['tornado', 'severe_wind', 'severe_hail', 'road_surface']\n",
    "OPTIONS = ['original', 'reduced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b860bf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Load the Data and Model \n",
    "dataset = 'tornado'\n",
    "option = 'reduced'\n",
    "model, X, y = load_data_and_model(dataset, option, DATA_BASE_PATH, MODEL_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77286eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample the dataset. \n",
    "X_sub, y_sub = subsampler(X,y,SIZE)\n",
    "features = list(X.columns)\n",
    "est_name = model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af75719",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = skexplain.ExplainToolkit(model, X_sub, y_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307e0d9",
   "metadata": {},
   "source": [
    "### 1. ALE variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c98bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9962abd164142cf96e89c9652859ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ALE Numerical Features:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute ALE \n",
    "ale = explainer.ale(features='all', n_bootstrap=N_BOOTSTRAP, n_bins=N_BINS)\n",
    "# Compute the variance. \n",
    "ale_var = explainer.ale_variance(ale)\n",
    "# Convert to feature rankings \n",
    "ale_rank = to_skexplain_importance(ale_var[f'ale_variance_scores__{est_name}'].values, \n",
    "                                          est_name, features, method='ale_variance', normalize=True)\n",
    "\n",
    "# Save the raw ALE and ALE-variance rankings results for paper 1 \n",
    "explainer.save(os.path.join(RESULTS_PATH, f'ale_{dataset}_{option}.nc'), ale)\n",
    "explainer.save(os.path.join(RESULTS_PATH, f'ale_rank_{dataset}_{option}.nc'), ale_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb7c23",
   "metadata": {},
   "source": [
    "## 2-5. Flavors of Permutation Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3e868e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Perm. Imp.:   0%|                                                                                                                                                     | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Perm. Imp.:   7%|██████████                                                                                                                                   | 1/14 [00:01<00:19,  1.51s/it]\u001b[A\n",
      "Perm. Imp.:  14%|████████████████████▏                                                                                                                        | 2/14 [00:03<00:19,  1.60s/it]\u001b[A\n",
      "Perm. Imp.:  21%|██████████████████████████████▏                                                                                                              | 3/14 [00:04<00:17,  1.61s/it]\u001b[A\n",
      "Perm. Imp.:  29%|████████████████████████████████████████▎                                                                                                    | 4/14 [00:06<00:15,  1.58s/it]\u001b[A\n",
      "Perm. Imp.:  36%|██████████████████████████████████████████████████▎                                                                                          | 5/14 [00:07<00:13,  1.55s/it]\u001b[A\n",
      "Perm. Imp.:  43%|████████████████████████████████████████████████████████████▍                                                                                | 6/14 [00:09<00:12,  1.55s/it]\u001b[A\n",
      "Perm. Imp.:  50%|██████████████████████████████████████████████████████████████████████▌                                                                      | 7/14 [00:10<00:10,  1.51s/it]\u001b[A\n",
      "Perm. Imp.:  57%|████████████████████████████████████████████████████████████████████████████████▌                                                            | 8/14 [00:12<00:08,  1.47s/it]\u001b[A\n",
      "Perm. Imp.:  64%|██████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 9/14 [00:13<00:07,  1.41s/it]\u001b[A\n",
      "Perm. Imp.:  71%|████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 10/14 [00:14<00:05,  1.37s/it]\u001b[A\n",
      "Perm. Imp.:  79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 11/14 [00:15<00:03,  1.32s/it]\u001b[A\n",
      "Perm. Imp.:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 12/14 [00:17<00:02,  1.28s/it]\u001b[A\n",
      "Perm. Imp.:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 13/14 [00:18<00:01,  1.25s/it]\u001b[A\n",
      "Perm. Imp.: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:19<00:00,  1.39s/it]\u001b[A\n",
      "\n",
      "Perm. Imp.:   0%|                                                                                                                                                     | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Perm. Imp.:   7%|██████████                                                                                                                                   | 1/14 [00:01<00:20,  1.56s/it]\u001b[A\n",
      "Perm. Imp.:  14%|████████████████████▏                                                                                                                        | 2/14 [00:03<00:18,  1.55s/it]\u001b[A\n",
      "Perm. Imp.:  21%|██████████████████████████████▏                                                                                                              | 3/14 [00:04<00:16,  1.54s/it]\u001b[A\n",
      "Perm. Imp.:  29%|████████████████████████████████████████▎                                                                                                    | 4/14 [00:06<00:15,  1.58s/it]\u001b[A\n",
      "Perm. Imp.:  36%|██████████████████████████████████████████████████▎                                                                                          | 5/14 [00:07<00:14,  1.56s/it]\u001b[A\n",
      "Perm. Imp.:  43%|████████████████████████████████████████████████████████████▍                                                                                | 6/14 [00:09<00:12,  1.53s/it]\u001b[A\n",
      "Perm. Imp.:  50%|██████████████████████████████████████████████████████████████████████▌                                                                      | 7/14 [00:10<00:10,  1.48s/it]\u001b[A\n",
      "Perm. Imp.:  57%|████████████████████████████████████████████████████████████████████████████████▌                                                            | 8/14 [00:12<00:08,  1.44s/it]\u001b[A\n",
      "Perm. Imp.:  64%|██████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 9/14 [00:13<00:07,  1.41s/it]\u001b[A\n",
      "Perm. Imp.:  71%|████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 10/14 [00:14<00:05,  1.38s/it]\u001b[A\n",
      "Perm. Imp.:  79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 11/14 [00:15<00:03,  1.32s/it]\u001b[A\n",
      "Perm. Imp.:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 12/14 [00:16<00:02,  1.26s/it]\u001b[A\n",
      "Perm. Imp.:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 13/14 [00:18<00:01,  1.23s/it]\u001b[A\n",
      "Perm. Imp.: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:19<00:00,  1.36s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# Compute the permutatation importance (forward, backward, single-pass, multi-pass)\n",
    "explainer = skexplain.ExplainToolkit(model, X_sub, y_sub)\n",
    "DIRECTIONS = ['forward', 'backward']\n",
    "n_vars = len(X.columns)\n",
    "\n",
    "for direction in DIRECTIONS: \n",
    "    results = explainer.permutation_importance(\n",
    "                                           n_vars=n_vars, \n",
    "                                           evaluation_fn=EVALUATION_FN,\n",
    "                                           n_permute=N_PERMUTE, \n",
    "                                           n_jobs=N_JOBS,\n",
    "                                           verbose=True,\n",
    "                                           random_seed=42, \n",
    "                                           direction=direction,\n",
    "                                              )\n",
    "    # The native output for skexplain (based on PermutationImportance) are the permuted scores\n",
    "    # (i.e., the scores after features are permuted). However, for this study, we need to convert \n",
    "    # the output to a proper importance scores (i.e., with respect to the original score such that higher \n",
    "    # values indicate higher importances). Though proper importance scores are often shown as ratios, we found \n",
    "    # the difference (e.g., original score - permuted score) provides better scores. Ratio data does not have \n",
    "    # favorable properties for importance scores. Additionally, we normalize the importance scores \n",
    "    # for comparison across the different methods. \n",
    "    est_name = model[0]\n",
    "    if direction == 'backward':\n",
    "        # Backward multipass: 1 + (permute score - original score)\n",
    "        # Backward singlepass: original_score - permuted score\n",
    "        original_score = results[f'original_score__{est_name}'].values\n",
    "        scores = 1.0 + (results[f'backward_multipass_scores__{est_name}'].values - original_score)\n",
    "        norm_scores = normalize_importance(scores)\n",
    "        results[f'backward_multipass_scores__{est_name}'] = (['n_vars_multipass', 'n_permute'], norm_scores)\n",
    "    \n",
    "        original_score = results[f'original_score__{est_name}'].values\n",
    "        scores = original_score - results[f'backward_singlepass_scores__{est_name}'].values\n",
    "        norm_scores = normalize_importance(scores)\n",
    "        results[f'backward_singlepass_scores__{est_name}'] = (['n_vars_singlepass', 'n_permute'], norm_scores)\n",
    "    \n",
    "    else: \n",
    "        # Forward Multiplass: original_score - permuted score\n",
    "        # Forward Singlepass: 1 + (permute score - original score)\n",
    "        original_score = results[f'original_score__{est_name}'].values\n",
    "        scores = 1.0 + (results[f'forward_singlepass_scores__{est_name}'].values - original_score)\n",
    "        norm_scores = normalize_importance(scores)\n",
    "        results[f'forward_singlepass_scores__{est_name}'] = (['n_vars_singlepass', 'n_permute'], norm_scores)\n",
    "        \n",
    "        original_score = results[f'original_score__{est_name}'].values\n",
    "        scores = original_score - results[f'forward_multipass_scores__{est_name}'].values\n",
    "        norm_scores = normalize_importance(scores)\n",
    "        results[f'forward_multipass_scores__{est_name}'] = (['n_vars_multipass', 'n_permute'], norm_scores)\n",
    "        \n",
    "    # Save the results \n",
    "    explainer.save(os.path.join(RESULTS_PATH, f'perm_imp_rank_{direction}_{dataset}_{option}.nc'), results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb33c8",
   "metadata": {},
   "source": [
    "## 4. Partial Dependence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34454150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ced8913a3f40838547c2f3f46bd3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PD Numerical Features:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute PD \n",
    "pd = explainer.pd(features='all', n_bootstrap=N_BOOTSTRAP, n_bins=N_BINS)\n",
    "# Compute the variance. \n",
    "pd_var = explainer.pd_variance(pd)\n",
    "# Convert to feature rankings \n",
    "pd_rank = to_skexplain_importance(pd_var[f'pd_variance_scores__{est_name}'].values, \n",
    "                                           est_name, features, method='pd_variance', normalize=True)\n",
    "\n",
    "# Save the raw PD and PD-variance rankings results for paper 1 \n",
    "explainer.save(os.path.join(RESULTS_PATH, f'pd_{dataset}_{option}.nc'), pd)\n",
    "explainer.save(os.path.join(RESULTS_PATH, f'pd_rank_{dataset}_{option}.nc'), pd_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98153f64",
   "metadata": {},
   "source": [
    "## 5. Model-Specific (Gini Impurity and Regression Coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c7ade92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-specific \n",
    "# Get the logistic regression coefficients\n",
    "if dataset == 'road_surface':\n",
    "    if option == 'original':\n",
    "        gini_values = model[1].base_estimator_.feature_importances_\n",
    "    else:\n",
    "        gini_values = model[1].base_estimator.named_steps['model'].feature_importances_\n",
    "    \n",
    "    gini_rank = to_skexplain_importance(gini_values,\n",
    "                                       estimator_name='Random Forest', \n",
    "                                       feature_names=features, \n",
    "                                         method = 'gini')\n",
    "    \n",
    "    # Save the random forest importances.\n",
    "    explainer.save(os.path.join(RESULTS_PATH, f'gini_rank_{dataset}_{option}.nc'), gini_rank)\n",
    "    \n",
    "else:    \n",
    "    coefs = model[1].base_estimator.named_steps['model'].coef_[0]\n",
    "    coef_rank = to_skexplain_importance(coefs,\n",
    "                                       estimator_name=est_name, \n",
    "                                       feature_names=features, \n",
    "                                       method = 'coefs')\n",
    "    \n",
    "    # Save the log. regress. importances.\n",
    "    explainer.save(os.path.join(RESULTS_PATH, f'coef_rank_{dataset}_{option}.nc'), coef_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55826a92",
   "metadata": {},
   "source": [
    "## 6. SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb4c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SHAP (Approx. Owen Values)\n",
    "# The default explainer is the PermutationExplainer. The PermutationExplainer uses a \n",
    "# simple forward- and backward-permutation scheme to compute the SHAP values. \n",
    "# The SHAP documentation claims this method is exact for 2nd order interactions.\n",
    "# For the maskers, we are using correlations and as such we are computing \n",
    "# approximate Owen values. \n",
    "\n",
    "# Check if each SHAP example can be ran in parallel. \n",
    "results = explainer.local_attributions('shap', \n",
    "                                       shap_kws={'masker' : \n",
    "                                      shap.maskers.Partition(X, max_samples=100, \n",
    "                                                             clustering=\"correlation\"), \n",
    "                                     'algorithm' : 'permutation'})\n",
    "\n",
    "\n",
    "shap_rank = to_skexplain_importance(results[f'shap_values__{est_name}'].values, \n",
    "                                     estimator_name=est_name, \n",
    "                                     feature_names=features, \n",
    "                                     method ='shap_sum')\n",
    "\n",
    "# Sum the SHAP values for each feature and then save results. \n",
    "explainer.save(os.path.join(RESULTS_PATH, f'shap_{dataset}_{option}.nc'), results)\n",
    "explainer.save(os.path.join(RESULTS_PATH, f'shap_rank_{dataset}_{option}.nc'), shap_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6474d1",
   "metadata": {},
   "source": [
    "## 7. SAGE Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4fe37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SAGE\n",
    "sage_values = compute_sage(model[1], X_sub.values, y_sub, X)\n",
    "sage_rank = to_skexplain_importance(sage_values,\n",
    "                                     estimator_name=est_name, \n",
    "                                     feature_names=features, \n",
    "                                     method = 'sage')\n",
    "\n",
    "# Sum the SAGE values for each feature and then save results. \n",
    "explainer.save(os.path.join(RESULTS_PATH, f'sage_rank_{dataset}_{option}.nc'), sage_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b387e",
   "metadata": {},
   "source": [
    "## 8. Tree Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac44d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'road_surface':\n",
    "    results = explainer.local_attributions('tree_interpreter')\n",
    "\n",
    "    ti_rank = to_skexplain_importance(results[f'tree_interpreter_values__{est_name}'].values, \n",
    "                                     estimator_name=est_name, \n",
    "                                     feature_names=features, \n",
    "                                     method ='tree_interpreter')\n",
    "\n",
    "    # Sum the SHAP values for each feature and then save results. \n",
    "    explainer.save(os.path.join(RESULTS_PATH, f'ti_{dataset}_{option}.nc'), results)\n",
    "    explainer.save(os.path.join(RESULTS_PATH, f'ti_rank_{dataset}_{option}.nc'), ti_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f53048",
   "metadata": {},
   "source": [
    "## 9. LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a29536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the LIME, we must provide the training dataset. We also denote any categorical features. \n",
    "if dataset == 'road_surface':\n",
    "    lime_kws = {'training_data' : X.values, 'categorical_names' : ['rural', 'urban']}\n",
    "else:\n",
    "    lime_kws = {'training_data' : X.values}\n",
    "\n",
    "results = explainer.local_attributions('lime', lime_kws=lime_kws)\n",
    "\n",
    "lime_rank = to_skexplain_importance(results[f'lime_values__{est_name}'].values, \n",
    "                                     estimator_name=est_name, \n",
    "                                     feature_names=features, \n",
    "                                     method ='lime')\n",
    "\n",
    "# Sum the SHAP values for each feature and then save results. \n",
    "explainer.save(os.path.join(RESULTS_PATH, f'lime_{dataset}_{option}.nc'), results)\n",
    "explainer.save(os.path.join(RESULTS_PATH, f'lime_rank_{dataset}_{option}.nc'), lime_rank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
